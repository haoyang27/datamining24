{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "# Load CSV data into NumPy arrays\n",
    "def load_data(file_path, selected_columns, target_column):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        headers = next(reader)  # Read the header row\n",
    "        selected_indices = [headers.index(col) for col in selected_columns]\n",
    "        target_index = headers.index(target_column)\n",
    "        \n",
    "        for row in reader:\n",
    "            data.append([float(row[i]) if row[i].isdigit() else row[i] for i in selected_indices + [target_index]])\n",
    "    data = np.array(data, dtype=object)\n",
    "    X = np.array(data[:, :-1], dtype=float)  # Features\n",
    "    y = np.array(data[:, -1], dtype=float)  # Target variable\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X, y):\n",
    "    \"\"\"Normalize features and target to have mean 0 and standard deviation 1.\"\"\"\n",
    "    X_mean = np.mean(X, axis=0) # Mean of each column\n",
    "    X_std = np.std(X, axis=0) # Standard deviation of each column\n",
    "    y_mean = np.mean(y) # Mean of target\n",
    "    y_std = np.std(y) # Standard deviation of target\n",
    "    \n",
    "    X_normalized = (X - X_mean) / X_std # Normalized features\n",
    "    y_normalized = (y - y_mean) / y_std # Normalized target\n",
    "    return X_normalized, y_normalized, X_mean, X_std, y_mean, y_std # Return the normalization parameters\n",
    "\n",
    "\n",
    "\n",
    "def lasso_regression(X, y, alpha, iterations=1000, learning_rate=0.001):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n) # Initialize the weights\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        predictions = X @ theta # Make predictions\n",
    "        mse_loss = np.mean((y - predictions) ** 2)  # MSE\n",
    "        gradient = (-2 / m) * (X.T @ (y - predictions)) + (alpha / m) * np.sign(theta) # L1 regularization, L1 norm\n",
    "        theta -= learning_rate * gradient # Update the weights\n",
    "    \n",
    "    return theta\n",
    "\n",
    "\n",
    "def ridge_regression(X, y, alpha, iterations=1000, learning_rate=0.001):\n",
    "    m, n = X.shape\n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        predictions = X @ theta\n",
    "        mse_loss = np.mean((y - predictions) ** 2)  # MSE\n",
    "        gradient = (-2 / m) * (X.T @ (y - predictions)) + (2 * alpha / m) * theta # L2 regularization, squared L2 norm\n",
    "        theta -= learning_rate * gradient\n",
    "    \n",
    "    return theta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_features(X, degree):\n",
    "    \"\"\"Generate polynomial features up to the given degree.\"\"\"\n",
    "    X_poly = X\n",
    "    for d in range(2, degree + 1):\n",
    "        X_poly = np.hstack((X_poly, X ** d)) # Add higher-order features\n",
    "    return X_poly\n",
    "\n",
    "def polynomial_regression(X, y, degree):\n",
    "    \"\"\"Train polynomial regression using the normal equation.\"\"\"\n",
    "    X_poly = polynomial_features(X, degree) # Generate polynomial features\n",
    "    X_poly, _, _, _, _, _ = normalize(X_poly, y)  # Normalize expanded features\n",
    "    theta = np.linalg.inv(X_poly.T @ X_poly) @ X_poly.T @ y # Normal equation\n",
    "    return theta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_with_theta(X, y, model, model_params, folds=5, y_mean=0, y_std=1):\n",
    "    fold_size = len(X) // folds\n",
    "    errors = []\n",
    "    best_theta = None\n",
    "    \n",
    "    for i in range(folds):\n",
    "        # Split data into train and validation sets\n",
    "        X_val = X[i * fold_size:(i + 1) * fold_size]\n",
    "        y_val = y[i * fold_size:(i + 1) * fold_size]\n",
    "        X_train = np.vstack((X[:i * fold_size], X[(i + 1) * fold_size:]))\n",
    "        y_train = np.hstack((y[:i * fold_size], y[(i + 1) * fold_size:]))\n",
    "        \n",
    "        # Train the model\n",
    "        if model == \"lasso\":\n",
    "            theta = lasso_regression(X_train, y_train, **model_params)\n",
    "        elif model == \"ridge\":\n",
    "            theta = ridge_regression(X_train, y_train, **model_params)\n",
    "        elif model == \"polynomial\":\n",
    "            degree = model_params['degree']\n",
    "            theta = polynomial_regression(X_train, y_train, degree)\n",
    "        \n",
    "        # Predict and calculate error (denormalize predictions)\n",
    "        if model == \"polynomial\":\n",
    "            X_val_poly = polynomial_features(X_val, model_params['degree'])\n",
    "            X_val_poly, _, _, _, _, _ = normalize(X_val_poly, y_val)\n",
    "            predictions = X_val_poly @ theta\n",
    "        else:\n",
    "            predictions = X_val @ theta\n",
    "        \n",
    "        predictions = predictions * y_std + y_mean  # Denormalize predictions\n",
    "        error = np.mean((y_val * y_std + y_mean - predictions) ** 2)  # Calculate denormalized MSE\n",
    "        errors.append(error)\n",
    "        \n",
    "        # Store the last theta (trained on the last fold)\n",
    "        best_theta = theta\n",
    "    \n",
    "    print(f\"Model: {model}, Fold Errors: {errors}\")\n",
    "    return np.mean(errors), best_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: lasso, Fold Errors: [8.630143682013461, 7.375695718310576, 7.268288748071142, 7.203875734980572, 5.755651636194513]\n",
      "Lasso Regression Error: 7.246731103914053\n",
      "Model: ridge, Fold Errors: [8.630134278861314, 7.3756850929335815, 7.268282009963958, 7.203865559227341, 5.755636498761594]\n",
      "Ridge Regression Error: 7.246720687949558\n",
      "Model: polynomial, Fold Errors: [8.549712865731061, 7.2398728295203965, 7.1850819893227404, 7.053220144742656, 5.515896936720181]\n",
      "Polynomial Regression Error: 7.108756953207407\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # File path and columns\n",
    "    file_path = '/data/haoyang27/data_mining/StudentPerformanceFactors_Cleaned.csv'  # Replace with your file path\n",
    "    selected_columns = ['Hours_Studied', 'Attendance']  # Replace with your chosen features\n",
    "    target_column = 'Exam_Score'  # Replace with your target column\n",
    "    \n",
    "    # Load and normalize data\n",
    "    X, y = load_data(file_path, selected_columns, target_column)\n",
    "    X, y, X_mean, X_std, y_mean, y_std = normalize(X, y)\n",
    "    \n",
    "    # Train and save theta for Lasso\n",
    "    lasso_error, theta_lasso = cross_validation_with_theta(\n",
    "        X, y, model=\"lasso\", model_params={\"alpha\": 0.1}, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "    print(\"Lasso Regression Error:\", lasso_error)\n",
    "    \n",
    "    # Train and save theta for Ridge\n",
    "    ridge_error, theta_ridge = cross_validation_with_theta(\n",
    "        X, y, model=\"ridge\", model_params={\"alpha\": 0.1}, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "    print(\"Ridge Regression Error:\", ridge_error)\n",
    "    \n",
    "    # Train and save theta for Polynomial Regression\n",
    "    poly_error, theta_poly = cross_validation_with_theta(\n",
    "        X, y, model=\"polynomial\", model_params={\"degree\": 2}, y_mean=y_mean, y_std=y_std\n",
    "    )\n",
    "    print(\"Polynomial Regression Error:\", poly_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_input, model, model_params, theta, X_mean, X_std, y_mean, y_std):\n",
    "    \"\"\"\n",
    "    Predict the exam score given input features.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_input: Raw input features (not normalized)\n",
    "    - model: The model type (\"lasso\", \"ridge\", or \"polynomial\")\n",
    "    - model_params: The parameters used to train the model\n",
    "    - theta: The trained parameters\n",
    "    - X_mean, X_std: The mean and std of the features used during training\n",
    "    - y_mean, y_std: The mean and std of the target variable during training\n",
    "    \n",
    "    Returns:\n",
    "    - Predicted exam score (denormalized)\n",
    "    \"\"\"\n",
    "    # Normalize the input features\n",
    "    X_input_normalized = (X_input - X_mean) / X_std\n",
    "\n",
    "    # For polynomial regression, expand features\n",
    "    if model == \"polynomial\":\n",
    "        degree = model_params['degree']\n",
    "        X_input_normalized = polynomial_features(X_input_normalized, degree)\n",
    "\n",
    "    # Compute predictions\n",
    "    predictions_normalized = X_input_normalized @ theta\n",
    "    \n",
    "    # Denormalize the predictions\n",
    "    predictions = predictions_normalized * y_std + y_mean\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Exam Score (Lasso): [71.28409414]\n",
      "Predicted Exam Score (Ridge): [71.28411431]\n",
      "Predicted Exam Score (Polynomial): [71.84380941]\n"
     ]
    }
   ],
   "source": [
    "# Example input: Hours_Studied and Attendance for a new student\n",
    "X_input = np.array([[24, 98]])  # Replace with actual input features\n",
    "\n",
    "# Predict using Lasso\n",
    "predicted_lasso = predict(\n",
    "    X_input,\n",
    "    model=\"lasso\",\n",
    "    model_params={\"alpha\": 0.1},\n",
    "    theta=theta_lasso,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std,\n",
    ")\n",
    "print(\"Predicted Exam Score (Lasso):\", predicted_lasso)\n",
    "\n",
    "# Predict using Ridge\n",
    "predicted_ridge = predict(\n",
    "    X_input,\n",
    "    model=\"ridge\",\n",
    "    model_params={\"alpha\": 0.1},\n",
    "    theta=theta_ridge,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std,\n",
    ")\n",
    "print(\"Predicted Exam Score (Ridge):\", predicted_ridge)\n",
    "\n",
    "# Predict using Polynomial\n",
    "predicted_poly = predict(\n",
    "    X_input,\n",
    "    model=\"polynomial\",\n",
    "    model_params={\"degree\": 2},\n",
    "    theta=theta_poly,\n",
    "    X_mean=X_mean,\n",
    "    X_std=X_std,\n",
    "    y_mean=y_mean,\n",
    "    y_std=y_std,\n",
    ")\n",
    "print(\"Predicted Exam Score (Polynomial):\", predicted_poly)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
